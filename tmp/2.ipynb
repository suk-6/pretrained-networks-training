{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import torchvision.transforms as T\n",
    "import torch.utils.data as data\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "rootDataset = os.path.join('/', 'home', 'dblab', 'coco')\n",
    "\n",
    "trainAnnoPath = os.path.join(rootDataset, 'annotations', 'instances_train2017.json')\n",
    "traincategoryPath = os.path.join(rootDataset, 'annotations', 'categories.json')\n",
    "trainImagePath = os.path.join(rootDataset, 'train2017')\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((480, 640)),\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "trainDataset = dset.CocoDetection(root=trainImagePath, annFile=trainAnnoPath)\n",
    "\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoCoDataset(data.Dataset):\n",
    "    def __init__(self, categoryPath, input_transform=None, labels_path=None):\n",
    "        self.coco = trainDataset\n",
    "        with open(categoryPath,'r') as load_category:\n",
    "            self.category_map = json.load(load_category)\n",
    "        self.input_transform = input_transform\n",
    "        self.labels_path = labels_path\n",
    "\t\n",
    "        self.labels = []\n",
    "        if self.labels_path:\n",
    "            self.labels = np.load(self.labels_path).astype(np.float64)\n",
    "            self.labels = (self.labels > 0).astype(np.float64)\n",
    "        else:\n",
    "            l = len(self.coco)\n",
    "            for i in range(l):\n",
    "                item = self.coco[i]\n",
    "                print(i)\n",
    "                categories = self.getCategoryList(item[1])\n",
    "                label = self.getLabelVector(categories)\n",
    "                self.labels.append(label)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = self.coco[index][0]\n",
    "        if self.input_transform:\n",
    "            input = self.input_transform(input)\n",
    "        return input, self.labels[index]\n",
    "\n",
    "\n",
    "    def getCategoryList(self, item):\n",
    "        categories = set()\n",
    "        for t in item:\n",
    "            categories.add(t['category_id'])\n",
    "        return list(categories)\n",
    "\n",
    "    def getLabelVector(self, categories):\n",
    "        label = np.zeros(80)\n",
    "        label_num = len(categories)\n",
    "        for c in categories:\n",
    "            index = self.category_map[str(c)]-1\n",
    "            label[index] = 1.0 / label_num\n",
    "        return label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet50(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "lr = 0.0001\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': epochs,\n",
    "    'optimizer': optimizer,\n",
    "    'loss_function': loss_function,\n",
    "    'trainDataloader': trainDataLoader,\n",
    "    'device': device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    trainDataloader=params[\"trainDataloader\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        for i, data in enumerate(trainDataloader, 0):\n",
    "            # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
    "            images, labels = data\n",
    "            images = list(F.to_tensor(image).to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            # inputs = torch.stack(inputs)\n",
    "            # inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치를 초기화\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + back propagation 연산\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 학습 결과 출력\n",
    "        print('Epoch: %d/%d, Train loss: %.6f' % (epoch+1, epochs, train_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.optim import SGD\n",
    "import os\n",
    "\n",
    "# 데이터셋과 어노테이션 디렉토리 경로\n",
    "data_dir = os.path.join('/', 'home', 'dblab', 'coco')\n",
    "train_dir = os.path.join(rootDataset, 'train2017')\n",
    "val_dir = os.path.join(rootDataset, 'val2017')\n",
    "anno_path = os.path.join(rootDataset, 'annotations', 'instances_train2017.json')\n",
    "\n",
    "# 변환 및 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# COCO 데이터셋 불러오기\n",
    "train_dataset = CocoDetection(root=os.path.join(data_dir, train_dir), annFile=anno_path, transform=transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 및 손실 함수, 옵티마이저 정의\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 91  # COCO dataset의 클래스 수\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        print(targets)\n",
    "        targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {losses.item()}')\n",
    "\n",
    "# 학습이 완료된 모델을 저장\n",
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_coco.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
